# data-science-Q-A

###data science questions
https://towardsdatascience.com/over-100-data-scientist-interview-questions-and-answers-c5a66186769a

###random forest 
https://mljar.com/blog/feature-importance-in-random-forest/


###gini impurity

Gini Impurity is the probability of incorrectly classifying a randomly chosen element in the dataset if it were randomly labeled according to the class distribution in the dataset. It's calculated as. G = ∑ i = 1 C p ( i ) ∗ ( 1 − p ( i ) ) G = \sum_{i=1}^C p(i) * (1 - p(i)) G=i=1∑Cp(i)∗(1−p(i))


###one-vs-rest method
https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/


###PCA
Principal component analysis (PCA) is a technique for reducing the dimensionality of such datasets, increasing interpretability but at the same time minimizing information loss. It does so by creating new uncorrelated variables that successively maximize variance.


###kernal easy explanation
The arguably simplest example is the linear kernel, also called dot-product. Given two vectors, the similarity is the length of the projection of one vector on another.
one dimentional vector x1y1+x2y2 transforms to two dimentional vectors (x1,x2) and (y1,y2)
![image](https://user-images.githubusercontent.com/55392634/147890840-7cc5b335-cd28-43cd-b198-99e40fff8bd6.png)
